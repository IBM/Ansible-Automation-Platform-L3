{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Acknowledgements Special thanks to Stephan Navarro for authoring the original version of this hands-on lab, \"Deploying WebSphere Application Server on AIX using Ansible Automation\" for IBM Client Engineering for Systems (Montpellier). In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . Automation of nearly any infrastructure endpoint with minimal amounts of code has immense practical value to a world increasingly dependent on clouds operated by different vendors, in varying countries, across multiple premises. Furthermore, these automation capabilities translate to a number of benefits for you and your business: reduced storage and resource burden placed on the machines to be automated; a much smaller footprint on these endpoints that could be hacked or exploited by malicious users; and most importantly, a greatly simplified approach to automation. Likewise, as environments change and operating systems advance over time, the automation jobs underway can be easily modified in lockstep as well. Adaptability and extensibility are key ingredients in the longevity of any technology \u2014 and fortunately the automation tooling for the hybrid multicloud era has those in abundance. Red Hat Ansible Automation Platform (AAP) commodifies the automation of everything else that applications, services, and containers need to run upon. That may include infrastructure provisioning, server deployments, IoT edge devices, script execution, and lots of other things that operations teams spend their time doing to \u201ckeep the lights on.\u201d It makes automation available to everyone with the lightest touch of human-readable snippets of code. More importantly to us, it makes automation of nearly everything needed to deliver the capabilities of the cloud possible, regardless of the destination. Who uses AAP today? Many different and potentially siloed personas: IT Operators : These include automation administrators responsible for ensuring that the automation platform is available to developers and implementors upstream within the organization. These individuals are generally concerned with the uptime of the automation platform, as any interruptions to service availability can directly impact upstream users. Platform Developers : These individuals are the automation \"plumbers\" who ensure that endpoints are viable for automation. Tasks and responsibilities include maintaining the AAP modules, plugins, and the Roles (content) to be used by platform users. They are the domain experts that are coding up collections which can later be extended or consumed by the end-users of the automation jobs. Platform Users : These are the automation \"writers,\" stitching together each automation task\u2014 Play by Play, task by task \u2014using content generated by the Platform Developers within their Playbooks. Essentially, this is configuration management applied to the management of IT estates. Instead of having a hardcoded script that instructs exactly how to move from task A to task B, you\u2019re creating a Playbook that lays out the expected end state and asks Ansible to figure out the delta between the current and end state. But critically, Ansible will not move on to task B until all of the conditions required by task A have been satisfied. This is not only invaluable for debugging purposes; it also guarantees a consistency and predictability in how Ansible's automation tasks will be performed \u2014 something that you will come to keenly appreciate throughout the course of this hands-on material, as we incrementally add more tasks and automation jobs to Ansible Playbooks for execution. Together, these qualities have two profound implications for Ansible clients. First, it removes any ambiguity from the automation process (Ansible will execute your instructions in exactly the order you\u2019ve assigned). Second, it places the burden of deciding how to achieve the end states of tasks A and B on the automation engine itself, rather than requiring the user to explicitly define all the gory details themselves. When automation is made available to everyone, it becomes possible to automate everything. The series of hands-on tutorials and learning modules embedded in this Level 3 course are designed to provide IBM Sellers, IBM Technical Sellers, and Business Partners with the fluency to gain trusted advisor status with clients and the expertise to tailor live technological demonstrations for customers. Throughout Red Hat Ansible Automation Platform Level 3 for Sales and Technical Sales , you will utilize AAP in conjunction with IBM Power Systems infrastructure (PowerVC) to generate an IBM AIX-based virtual machine; subsequently, Ansible automation will be used to install and deploy a live WebSphere Application Server instance inside of the virtual machine. The various ways in which Ansible's automation can also be applied to operational and administrative tasks\u2014 such as modifying root user characteristics, setting filesystem sizes, installing pre-requisites drivers and libraries, as well as software deployments \u2014will also be explored. All modules are accompanied by recordings and narrated instructions, delivered by your team of authors. Be sure to watch these for a visual demonstration of how to perform the hands-on lab components. In particular, it is strongly recommended that IBM Sellers and Technical Sellers watch these recordings \u2014 they will be useful for you as you go about creating and recording your own Stand & Deliver presentations for Level 3 accreditation. Level 3 Accreditation To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. Business Partners must pass an accreditation quiz after completing the hands-on portion of the course. The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. IBM Sales and Technical Sales must develop and record a Stand & Deliver presentation. This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to achieve. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the environments and techniques of this lab. Specific criteria that must be demonstrated as part of the Stand & Deliver recordings is provided within the documentation that accompanies the Level 3 course.","title":"Introduction"},{"location":"#_1","text":"","title":""},{"location":"#red-hat-ansible-automation-platform-aap-commodifies-the-automation-of-everything-else-that-applications-services-and-containers-need-to-run-upon","text":"That may include infrastructure provisioning, server deployments, IoT edge devices, script execution, and lots of other things that operations teams spend their time doing to \u201ckeep the lights on.\u201d It makes automation available to everyone with the lightest touch of human-readable snippets of code. More importantly to us, it makes automation of nearly everything needed to deliver the capabilities of the cloud possible, regardless of the destination. Who uses AAP today? Many different and potentially siloed personas: IT Operators : These include automation administrators responsible for ensuring that the automation platform is available to developers and implementors upstream within the organization. These individuals are generally concerned with the uptime of the automation platform, as any interruptions to service availability can directly impact upstream users. Platform Developers : These individuals are the automation \"plumbers\" who ensure that endpoints are viable for automation. Tasks and responsibilities include maintaining the AAP modules, plugins, and the Roles (content) to be used by platform users. They are the domain experts that are coding up collections which can later be extended or consumed by the end-users of the automation jobs. Platform Users : These are the automation \"writers,\" stitching together each automation task\u2014 Play by Play, task by task \u2014using content generated by the Platform Developers within their Playbooks. Essentially, this is configuration management applied to the management of IT estates. Instead of having a hardcoded script that instructs exactly how to move from task A to task B, you\u2019re creating a Playbook that lays out the expected end state and asks Ansible to figure out the delta between the current and end state. But critically, Ansible will not move on to task B until all of the conditions required by task A have been satisfied. This is not only invaluable for debugging purposes; it also guarantees a consistency and predictability in how Ansible's automation tasks will be performed \u2014 something that you will come to keenly appreciate throughout the course of this hands-on material, as we incrementally add more tasks and automation jobs to Ansible Playbooks for execution. Together, these qualities have two profound implications for Ansible clients. First, it removes any ambiguity from the automation process (Ansible will execute your instructions in exactly the order you\u2019ve assigned). Second, it places the burden of deciding how to achieve the end states of tasks A and B on the automation engine itself, rather than requiring the user to explicitly define all the gory details themselves.","title":"Red Hat Ansible Automation Platform (AAP) commodifies the automation of everything else that applications, services, and containers need to run upon."},{"location":"#_2","text":"","title":""},{"location":"#when-automation-is-made-available-to-everyone-it-becomes-possible-to-automate-everything","text":"The series of hands-on tutorials and learning modules embedded in this Level 3 course are designed to provide IBM Sellers, IBM Technical Sellers, and Business Partners with the fluency to gain trusted advisor status with clients and the expertise to tailor live technological demonstrations for customers. Throughout Red Hat Ansible Automation Platform Level 3 for Sales and Technical Sales , you will utilize AAP in conjunction with IBM Power Systems infrastructure (PowerVC) to generate an IBM AIX-based virtual machine; subsequently, Ansible automation will be used to install and deploy a live WebSphere Application Server instance inside of the virtual machine. The various ways in which Ansible's automation can also be applied to operational and administrative tasks\u2014 such as modifying root user characteristics, setting filesystem sizes, installing pre-requisites drivers and libraries, as well as software deployments \u2014will also be explored. All modules are accompanied by recordings and narrated instructions, delivered by your team of authors. Be sure to watch these for a visual demonstration of how to perform the hands-on lab components. In particular, it is strongly recommended that IBM Sellers and Technical Sellers watch these recordings \u2014 they will be useful for you as you go about creating and recording your own Stand & Deliver presentations for Level 3 accreditation. Level 3 Accreditation To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. Business Partners must pass an accreditation quiz after completing the hands-on portion of the course. The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. IBM Sales and Technical Sales must develop and record a Stand & Deliver presentation. This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to achieve. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the environments and techniques of this lab. Specific criteria that must be demonstrated as part of the Stand & Deliver recordings is provided within the documentation that accompanies the Level 3 course.","title":"When automation is made available to everyone, it becomes possible to automate everything."},{"location":"Part%201/01%20Getting%20Started/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . You will require access to the IBM Technology Zone (ITZ) in order to reserve your environment and complete the hands-on training. If you do not yet have access or an account with the ITZ, you may register for one by visiting the following page: https://techzone.ibm.com The hands-on environment can be provisioned free-of-charge using the reservation portal: https://techzone.ibm.com/my/reservations/create/61aa2c69a5295f00185b77b2 Alternatively, you can provision the environment by navigating to the following ITZ Collection ( https://techzone.ibm.com/collection/ansible-hands-on-power ) and scrolling down until you locate the Environments \u2014 \"Click here to get your hands on lab\" tab. Clicking the blue \"Reserve\" tile will navigate your browser window to the same reservation panel as the link above. In order to complete your reservation of the PowerVC infrastructure with AAP pre-installed, you must fill out the following information: Name : Give your reservation a unique name. Purpose : Set to Practice / Self-Education Purpose Description : Provide a brief summary of how the environment will be used. Preferred Geography : Montpellier, France Start Date & Time : Select the time and date for when you plan to complete the hands-on material. End Date & Time : Select a time and date no more than 4 hours later than the Start Time. The environment has been capped at 4 hours, after which it will expire and de-provision. Completion times Four hours is more than enough time to complete the hands-on portion of the course work. Make sure you reserve for a period where you can give the lab 4 uninterrupted hours of your time \u2014 should you require additional time, you can reserve the lab again, but your progress from the previous attempt will be reset. When satisfied, click the Check Availability button at the bottom of the page to verify that resources are available for your requested time slot. If the check passes, you can finalize your reservation request by clicking Submit . Reservations take approximately 10-15 minutes to complete from the time that you click submit. If you navigate to the My Reservations tab of the ITZ ( https://techzone.ibm.com/my/reservations ), you can monitor the progress of your reservation. Wait until the environment tile describes the instance as \" Ready \" \u2014 accessing it too soon will lead to issues (or an outright failure) when connecting to the PowerVC instance. You will also receive a pair of emails to your inbox once the environment has successfully deployed, as shown here. The \"Demo Ready Notification\" email contains an important link (\"Click Here\") for accessing your Project Kit , which will be needed to obtain information about your PowerVC environment \u2014 hostname, address, login information, and so on. Click that link now to load the Project Kit in your browser window. The second \"Demo VPN Ready Notification\" email is our next order of business. You will need to configure a special VPN tunnel in order to connect to the demo PowerVC environment. VPN access This is different from the VPN access you may be using to connect to the IBM intranet and network. All participants must follow the instructions outlined below in order to connect to the environment. Without the correct VPN setup, you will be unable to SSH or remotely connect to the PowerVC instance. From the \"Demo VPN Ready Notification\" email, locate the \"Click Here\" hyperlink to download your OpenVPN certificate , which is unique to your account and environment. This certificate will only need to be downloaded and set up once; in the event that you need to re-provision a new environment at a later time, it won't be necessary to repeat these steps. Further down in the email are three links for setting up OpenVPN, for each of the major operating systems: Windows, Linux, and MacOS. Selecting an OpenVPN client It is recommended that you use Tunnelblick if using running MacOS, but you have the option of using other OpenVPN clients if you prefer. Select the option that matches your machine's operating system. Follow the instructions to install OpenVPN on your machine and use the OpenVPN certificate (linked from the same email) to establish the connection. Once installed and setup, OpenVPN will allow you to establish a private VPN tunnel to your PowerVC environment. Click the \"Connect\" button (or similar \u2014 the screenshots provided here are for Tunnelblick on MacOS). You can disregard warnings or errors that the application may throw. After connecting, you will be able to access the PowerVC GUI and SSH remotely into your PowerVC environment, which we will cover next. After connecting to the VPN tunnel, return to the \"Demo Ready Notification\" email (or the My Reservations tab on the ITZ) and follow the URL to your unique Project Kit page, similar to the one captured here. The Project Kit summarizes all of the relevant connection information you will need to access your PowerVC and Ansible environment. Scroll down the page until you reach the Usage Instructions table near the bottom of the page. The table contains two relevant rows: the first row \"PowerVC GUI\" contains information on how to connect to the PowerVC infrastructure; the second row \"Ansible ssh console\" details how to remotely connect to Ansible via SSH. You will be making use of both endpoints throughout the lab. As such, it's recommended that you copy the URLs for both the GUI and Ansible endpoints (note that they have different host addresses), as well as the userID and password values (they are identical across both environments). Let's try connecting remotely over SSH to the Ansible environment. Make sure that your OpenVPN connection is active, otherwise the connection attempt will timeout. To connect via SSH, it is recommended that you use Terminal (MacOS) or PuTTY (Windows). SSH and PuTTY for Windows users For detailed instructions on how to connect with PuTTY on Windows, reference the linked material. Connect via SSH using the following command: ssh userID@ansibleURL Replace the userID value with the one in the third column of the Project Kit table. Replace the ansibleURL with the URL in the second row + second column of the Project Kit table (for example, 10.3.44.171 in the screenshot provided\u2014 use the value unique to your project ). You will be prompted to provide a password : supply the value with the fourth column of the Project Kit table. Hit Return and wait for the connection to complete. If successful, your console will now be connected directly to the Ansible controller node! Test out the connection with the following command: pwd Then check to see which version of Ansible the controller node is currently running: ansible --version Everything's now set and in good shape for you to get to work on deploying your first virtual machine via Ansible on to the PowerVC infrastructure.","title":"Getting Started"},{"location":"Part%202/01%20Deploy%20a%20VM/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . Ansible, and in particular YAML (Yet Another Markup Language), is very particular about indentation and formatting \u2014 something as trivial as an extra whitespace or an incorrectly-indented line of code can cause the interpreter to parse the instructions differently, resulting in outcomes you may not desire. To streamline the lab as much as possible, a Git repository was created ahead of time with large portions of the Ansible scripts and constructs prepared ahead of time. You will still need to edit elements in each of these files, and the instructions to follow will guide you step by step (as though you were creating these documents from scratch yourself), but it's worth noting that by cloning the Git repository you will be saving yourself a lot of extra typing (and potential debugging). Everything is documented for you\u2014 so you can go about creating all of these documents and scripts from scratch, if you wish. If you are a SELLER , it is strongly recommend that you clone the Git repository, as it will save you time and keystrokes. If you are a TECHNICAL SELLER , it is recommended that you take the time to craft these files from scratch yourself and that you do not clone the Git repository. SELLERS Submit the following instruction to clone the prepared Git repository into your Ansible controller node: git clone --branch hybridcloudevent https://github.com/stephannavarro/ansiblewas.git TECHNICAL SELLERS You will need to manually create the ansiblewas directory yourself before continuing. This step was automatically performed for Sellers when they cloned the Git repository. You can do so by issuing the following instruction: mkdir ansiblewas Continue through the remainder of the instructions regardless of your job role. After the clone action has been completed, navigate to the newly-created ansiblewas directory. cd ansiblewas The next order of business is configuring the Ansible controller node (to which you are currently connected) with details about our PowerVC environment and how our project directories are organized. This can be done by modifying the ansible.cfg configuration file: vi ansible.cfg VI cheat sheet Throughout this lab, you will make extensive use of the VI text editor. If you're not familiar with this editor, you can quickly get up to speed using the following cheat sheet: https://www.cse.scu.edu/~yfang/coen11/vi-CheatSheet.pdf for reference. As a quick primer on how to use the VI editor: Navigate using the up/down and left/right arrows keys. Hover the blinking indicator over the point in the text you wish to modify. To start adding or deleting text, first press the I (as in \"indigo\") key. Then either start adding text as normal (you can also paste lines of code that you have copied to your clipboard using CTRL+V) or deleting text using backspace. Save your changes and exit a file by first pressing the ESC key, then typing :x (the full colon must come first) and hitting return. If you want to exit a file without saving changes, press ESC and type :quit! (with the exclamation point included at the end). Other shortcuts and commands are detailed in the cheat sheet linked above. Within the configuration file, you will see three values of note: inventory , remote_tmp , and host_key_checking . Their respective purposes are as follows: inventory will instruct Ansible on which directory the host file should be defined (we will be modifying this file shortly). remote_tmp instructs which directory to use on the remote system (needed by the AIX operating system). host_key_checking tells SSH to accept remote keys (which will streamline the lab for us later). The ansible.cfg definition is provided below for those who are crafting these files from scratch (instead of using the cloned Git repository). You do not need to make any modification to the ansible.cfg file. Use the ESC + :quit! command in the VI editor to exit the file without making changes. [defaults] inventory = ./hosts remote_tmp = /tmp host_key_checking = False We are now ready to install the Ansible OpenStack Python modules on to the Ansible controller node. The openstacksdk library is required in order for Ansible to be able to interact with the PowerVC infrastructure provisioned via the ITZ. The following command will take care of installing all of the necessary drivers and dependencies: pip3 install --user \"openstacksdk==0.51.0\" \"python-openstackclient==5.4.0\" dnspython dig With the dependencies taken care of, we're now ready to begin deployment of an AIX operating system partition atop of the PowerVC infrastructure provisioned earlier.","title":"Deploy a Virtual Machine"},{"location":"Part%202/01%20Deploy%20a%20VM/#_1","text":"","title":""},{"location":"Part%202/01%20Deploy%20a%20VM/#if-you-are-a-seller-it-is-strongly-recommend-that-you-clone-the-git-repository-as-it-will-save-you-time-and-keystrokes","text":"","title":"If you are a SELLER, it is strongly recommend that you clone the Git repository, as it will save you time and keystrokes."},{"location":"Part%202/01%20Deploy%20a%20VM/#if-you-are-a-technical-seller-it-is-recommended-that-you-take-the-time-to-craft-these-files-from-scratch-yourself-and-that-you-do-not-clone-the-git-repository","text":"SELLERS Submit the following instruction to clone the prepared Git repository into your Ansible controller node: git clone --branch hybridcloudevent https://github.com/stephannavarro/ansiblewas.git TECHNICAL SELLERS You will need to manually create the ansiblewas directory yourself before continuing. This step was automatically performed for Sellers when they cloned the Git repository. You can do so by issuing the following instruction: mkdir ansiblewas Continue through the remainder of the instructions regardless of your job role. After the clone action has been completed, navigate to the newly-created ansiblewas directory. cd ansiblewas The next order of business is configuring the Ansible controller node (to which you are currently connected) with details about our PowerVC environment and how our project directories are organized. This can be done by modifying the ansible.cfg configuration file: vi ansible.cfg VI cheat sheet Throughout this lab, you will make extensive use of the VI text editor. If you're not familiar with this editor, you can quickly get up to speed using the following cheat sheet: https://www.cse.scu.edu/~yfang/coen11/vi-CheatSheet.pdf for reference. As a quick primer on how to use the VI editor: Navigate using the up/down and left/right arrows keys. Hover the blinking indicator over the point in the text you wish to modify. To start adding or deleting text, first press the I (as in \"indigo\") key. Then either start adding text as normal (you can also paste lines of code that you have copied to your clipboard using CTRL+V) or deleting text using backspace. Save your changes and exit a file by first pressing the ESC key, then typing :x (the full colon must come first) and hitting return. If you want to exit a file without saving changes, press ESC and type :quit! (with the exclamation point included at the end). Other shortcuts and commands are detailed in the cheat sheet linked above. Within the configuration file, you will see three values of note: inventory , remote_tmp , and host_key_checking . Their respective purposes are as follows: inventory will instruct Ansible on which directory the host file should be defined (we will be modifying this file shortly). remote_tmp instructs which directory to use on the remote system (needed by the AIX operating system). host_key_checking tells SSH to accept remote keys (which will streamline the lab for us later). The ansible.cfg definition is provided below for those who are crafting these files from scratch (instead of using the cloned Git repository). You do not need to make any modification to the ansible.cfg file. Use the ESC + :quit! command in the VI editor to exit the file without making changes. [defaults] inventory = ./hosts remote_tmp = /tmp host_key_checking = False We are now ready to install the Ansible OpenStack Python modules on to the Ansible controller node. The openstacksdk library is required in order for Ansible to be able to interact with the PowerVC infrastructure provisioned via the ITZ. The following command will take care of installing all of the necessary drivers and dependencies: pip3 install --user \"openstacksdk==0.51.0\" \"python-openstackclient==5.4.0\" dnspython dig With the dependencies taken care of, we're now ready to begin deployment of an AIX operating system partition atop of the PowerVC infrastructure provisioned earlier.","title":"If you are a TECHNICAL SELLER, it is recommended that you take the time to craft these files from scratch yourself and that you do not clone the Git repository."},{"location":"Part%202/02%20Deploy%20an%20AIX%20Partition/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . The deployment of an AIX operating system partition on to the PowerVC infrastructure will be automated entirely via the Ansible control (master) node. Ansible will make use of the inventory we've defined, a Playbook that we will modify to paint the broad strokes for what automation is to be performed, and built-in Modules that are part of Ansible's engine to carry out those instructions. Ansible OpenStack Modules\u2014 downloaded in the previous step \u2014will allow Ansible to create an LPAR (logical partition) on the PowerVC infrastructure where the AIX operating system can reside. Begin modification of the OpenStack configuration file (located within your home directory on the Ansible control node) using the following instruction: vi clouds.yaml If you cloned the Git repository earlier, a template has already been crafted for you; otherwise, you will need to recreate it using the sample code below. Regardless of the route you take, you will need to modify the template to the specifications of your ITZ credentials and environment. The value idXXXXXXXX must be replaced with the username/ID that was recorded from the Project Kit page. The same holds true for other variables or fields that have been bolded below in the sample script: if it is highlighted in red text within the screenshot, you must modify the clouds.yaml script for those fields to your own specifications and then save the changes before moving on. Tips for the VI editor Remember: ESC and then :x followed by the Return key to save your work and exit the VI editor. The clouds.yaml template should look like the following screenshot. Modify as necessary to match the specifications of your unique ITZ environment. Update the userID, password, project name ( ansiblewas ), and the host address (this address should match the PowerVC GUI address from the Project Kit). clouds: idXXXXXXXX: auth: auth_url: https://10.3.44.65:5000/v3/ domain_name: Default username: idXXXXXXXX password: Provided_password project_name: ansiblewas verify: false Be careful about indentation Ansible is very particular about indentation and nesting rules. In this example, every indentation level is denoted by two whitespaces. Also be sure to preserve the empty newline at the end of this example (the empty final line must be present within your YAML manifest.) After modifying and saving the clouds.yaml manifest file, we need to define the Playbook which Ansible will execute against. Modify (or create) the Playbook for generating a virtual machine via the following: vi mkvm.yaml As before, adjust the template as necessary: you will need to substitute your own values for: user gather_facts cloud public_key_file cloud name key_name net-name Keys are automatically generated ahead of time The ansible_key_idXXXXXXXX and the public_key_file were created automatically for you by the IBM Technology Zone as part of your environment reservation. You do not need to generate or locate these files yourself \u2014 simply modify the idXXXXXXXX value to match your userID . The code template is available below for ease of copying and modifying your own variant: --- - hosts: localhost gather_facts: false vars: ansible_connection: local tasks: - name: adding ssh key to powervc os_keypair: cloud: idXXXXXXXX state: present name: ansible_key_idXXXXXXXX public_key_file: /home/idXXXXXXXX/.ssh/id_rsa.pub - name: Create a new VM instance os_server: cloud: idXXXXXXXX timeout: 900 state: present name: vmidXXXXXXXX image: AIX721_7022_300G_DEMO flavor: was key_name: ansible_key_idXXXXXXXX nics: - net-name: VLAN344 register: vm - name: Showing newly assigned IP address debug: msg: the IP address is \"{{ vm.server.public_v4 }}\" - name: Waits for SSH port 22 to open wait_for: host: \"{{ vm.server.public_v4 }}\" delay: 5 port: 22 sleep: 10 timeout: 900 Line 11 For the ' name ' field (line 11) you must include both vm + idXXXXXXXXX ( do not forget to prefix with vm ) in your manifest. The ' name ' variable will appear as BLANK when working from the Git repository clone \u2014 both sellers and technical sellers must complete this variable definition regardless of whether they are working from the Git repository clone or not. Line 16 The ' net-name ' field (line 16) must be set equal to VLAN344 , if it hasn't already been by default. Save and exit the mkvm.yaml Playbook once satisfied. Let's take a moment, before moving on, to parse out what some of these fields and modifications have done. os_keypair : Allows Ansible to upload your account's public SSH key to PowerVC, which will be used at deployment time to ensure that we won't need to use password authentication in the future. os_server : Creates the virtual machine on the cloud name defined within the clouds.yaml manifest file. debug : Will print to screen the IP address assigned to PowerVC once deployed. Record this information for later. wait_for : Ensures that the virtual machine has had time to boot up and the SSH port to be opened before re-enabling prompts from the terminal. Before we get started with execution of the Playbook, open a Web browser on your local machine and navigate to the PowerVC GUI URL (in the first row of the Project Kit table), supplying your userID and password from the same table when prompted to log in. This will load a dashboard overview of your PowerVC infrastructure and all that is transpiring under the covers. Keep this tab open, as we can use it to track the progress of our virtual machine deployment over time. You may encounter a \"Connection is not private\" warning when attempting to access the website. Click \"visit this website\" at the bottom of the message (for Safari browsers), or ignore the warning if prompted to do so, and continue to the PowerVC GUI page. The dashboard will look similar to the one captured in the screenshot below. Time to execute the Playbook! Return to your Terminal console and submit the following command: ansible-playbook mkvm.yaml -v If everything goes smoothly, a virtual machine will be deployed to PowerVC in a matter of minutes. If you encounter errors or things don't go as planned \u2014 don't panic. Ansible, as warned about previously, is quite particular about things like indentation. A misplaced whitespace or a slipped finger on the keyboard can create a typo that will throw the script into disarray (after all, Ansible will try to execute your instructions exactly as you have written.) Go back into the scripts mentioned previously and verify that everything is correct and that all necessary substitutions have been made, then try executing the ansible-playbook instruction (above) a second time. While execution of the Playbook is underway, return to the PowerVC dashboard and click the VM List button from the taskbar on the left. Previously this tab would have displayed as empty. As the execution of the Playbook gets underway, a new virtual machine will be listed with the status of \" Building ;\" once the virtual machine has been deployed, the status will be adjusted to \" Active .\" Once the build task has completed and the status is set to \" Active ,\" the IP field of the table will be populated with the virtual machine's address. Record this information for later. Return to the Terminal console where you have SSH'd into the Ansible control node. Take note of the verbose logs that were returned for every stage of the Playbook execution. Within these logs you'll find details on various aspects of the virtual machine deployment, such as the Image ID (e.g. AIX721-7022-300G-DEMO ) for the AIX partition. If you return to the PowerVC dashboard and drill down into the Image List tab, you can locate the matching Image ID and inspect it for additional details. While you're on the dashboard, try exploring the Network ID (e.g. VL344 ) as well. Here you will find a table summarizing all of the networks defined with your PowerVC instance, including their VLAN IDs, Type, the number of VMs using that particular network connection, subnet masks, gateway IDs, and DNS server(s). Other areas of the PowerVC dashboard can also be explored, should you wish. When satisfied, we'll proceed with modifying the hosts file parameters on the Ansible control node using the newly-generated virtual machine IP address. The hosts file provides a list (an inventory, if you will) of the AIX partitions (the newly-generated virtual machine) where Ansible is to execute Playbook tasks. Edit the hosts file using the following statement: vi hosts As before, use the template already cloned from Git (or craft your own) and substitute the placeholder IP address with the one associated with the newly-deployed AIX virtual machine. was: hosts: 10.3.44.XX: remote_tmp: /tmp/ What is was ? The was variable is in reference to the Compute Template used by our PowerVC virtual machine deployment; it was defined ahead of time for the ITZ environment specifically to meet the resource requirements for WebSphere Application Server ( was ). You can drill down into the Compute Template tab from the PowerVC dashboard if you wish to inspect further details about it. In the following section, we'll set the stage for a full deployment of WebSphere Application Server atop of the AIX VM that is now running on PowerVC infrastructure.","title":"Deploy an AIX Partition using PowerVC"},{"location":"Part%203/01%20Laying%20the%20Groundwork/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . The preparations are complete and the groundwork has been set for a fully-automated installation and deployment of WebSphere Application Server (WAS) via AAP. At this stage, you have already used Ansible to deploy a virtual machine with an AIX partition atop of PowerVC infrastructure. Additional configurations will need to be made to that partition to prepare it for hosting a WAS deployment within it. These types of configuration changes are precisely the type of operational work that can be easily automated by Ansible, and a prime example of how businesses today are offloading administrative burdens through automation. In the following steps, you will instruct Ansible to perform the following operations: Change root user characteristics using the power_aix Ansible modules, downloaded via Ansible Galaxy. Change the /tmp filesystem size to 6GB Change the /var filesystem size to 2GB Change the /opt filesystem size to 4GB Change the /usr filesystem size to 6GB Install additional software and libraries such as zip, unzip, and gnu tar Generate a WebSphere installation response file Upload WAS binaries Install WAS Create a WAS profile Start WAS To proceed, you will first need to download an IBM Power Systems collection for AIX on Power via the Ansible Galaxy repository. To install these on the Ansible control node, invoke the following command using your SSH console: ansible-galaxy collection install ibm.power_aix Installation of the drivers should take only a moment to complete. Another handy feature of AAP is its ability to simplify how code is shared amongst teams, which traditionally becomes challenging and cumbersome at scale in the absence of automation. Ansible employs a feature known as \" Roles \" which in essence allows a developer to define a common set of configuration steps that can then be re-used repeatedly across multiple environments. Instead of having to coordinate across teams and share duplicate instructions with different groups, the developer can take the \"write once, run anywhere\" approach of defining an automation job a single time and then making repeated use of that code (consistently) across multiple environments. In our case, we will define an Ansible Role comprised of a set of tasks needed to configure a host (our AIX partition) for a service (WebSphere Application Server). Roles, like many other aspects of Ansible, are defined using YAML files with a predefined directory structure. Roles provide a way for you to make it easier to reuse Ansible code generically. You can package, in a standardized directory structure, all the tasks, variables, files, templates, and other resources needed to provision infrastructure or deploy applications. Copy that role from project to project simply by copying the directory. You can then simply call that role from a play to execute it. Roles carry the following benefits for developers and administrators: Roles group content, allowing easy sharing of code with others Roles can be written that define the essential elements of a system type: web server, database server, Git repository, or other purpose Roles make larger projects more manageable Roles can be developed in parallel by different administrators The directory structure is still something that we have yet to \"predefine\", so let's do that next. The directory structure of a Role contains directories such as defaults, vars, tasks, files, templates, meta, and handlers \u2014 these are all \"expected\" directories (we can make use of all of them or only a subset) that Ansible Roles must be patterned against. Each directory must contain a main.yml file which provides the relevant content needed by Ansible to execute a Playbook. Let's examine the purpose of each directory type, in turn: defaults : Contains default variables for the Role; variables by default have the lowest priority, so they are easy to override. vars : Contains variables for the Role; variables in vars have a higher priority than 'default' variables. tasks : Contains the main list of steps to be executed by the Role. files : Contains files which must be copied over to the remote host. templates : Contains file templates that support modifications from the Role; in our example, we will use the Jinja2 templating language for creating templates. meta : Contains metadata for the Role, including the author, supported platforms, and dependencies. handlers : Contains handlers which can be invoked by \"notify\" directives; these are associated with the service. Ansible supports variables that can be used to store values that can then be reused throughout files in an Ansible project. This can simplify the creation and maintenance of a project and reduce the number of errors. Variables provide a convenient way to manage dynamic values for a given environment in your Ansible project. Examples of values that variables might contain include: Users to create Packages to install Services to restart Files to remove Archives to retrieve from the internet The directory structure you are to define in the steps ahead will look similar to the following diagram, with two distinct Roles names ( aix and was ), and subdirectories nestled within those parents. Execute the following instructions via your SSH console, either one at a time or all as a single statement, to create the directory structure needed for the Roles. Navigate to the correct directory first Make sure you are sitting in the /ansiblewas directory before creating the following subdirectories! mkdir -p roles/aix/tasks mkdir -p roles/aix/defaults mkdir -p roles/aix/templates mkdir -p roles/was/tasks mkdir -p roles/was/defaults mkdir -p roles/was/templates With AIX installed on the PowerVC LPAR (logical partition), you next need to modify root user settings associated with the virtual machine to increase the size of the filesystems available to it, as well as install additional dependencies and drivers needed for the environment. You will do so with modifications to the Roles associated with \" aix \" via the main.yml manifest file. Modify (or view) the YAML file using the following command: vi roles/aix/tasks/main.yml As before, you can either view the contents of the manifest (if you cloned the Github repository earlier) or craft a new one from scratch using the following template. No modifications to the template will be needed at this time. When satisfied, press ESC following by :x and Return to save your changes and exit the VI editor. --- - name: modifying root capabilities ibm.power_aix.user: state: modify name: root attributes: fsize: -1 cpu: -1 data: -1 stack: -1 core: -1 rss: -1 nofiles: -1 fsize_hard: -1 - name: Changes /tmp to 6G size aix_filesystem: filesystem: /tmp size: 6G state: present - name: Changes /var to 2G size aix_filesystem: filesystem: /var size: 2G state: present - name: Changes /opt to 4G size aix_filesystem: filesystem: /opt size: 4G state: present - name: Changes /usr to 6G aix_filesystem: filesystem: /usr size: 6G state: present - name: installing zip, unzip, GNUtar using yum yum: name: unzip, zip, tar-1.32-1 state: latest - name: Creating staging directory file: path: /tmp/im state: directory You are now prepared to craft the Playbook that Ansible will use to automate the workflow just defined for the aix Role. Use the following command to edit (or create) the was Playbook for WebSphere Application Server: vi was.yml As before, you can either view the contents of the manifest (if you cloned the Github repository earlier) or craft a new one from scratch using the following template. If you are working from the cloned template, you may have noticed that the last line of the YAML file ( #- role: was ) has been commented out \u2014 leave this unchanged for now, as you will be returning to it shortly. For now we are only concerned with the successful execution of the jobs associated with the aix Role. The template for was.yml is as follows: --- - hosts: was gather_facts: true user: root collections: - ibm.power_aix roles: - role: aix #- role: was Ansible facts are variables that are automatically discovered by Ansible on a managed host. Facts contain host-specific information that can be used just like regular variables in plays, conditionals, loops, or any other statement that depends on a value collected from a managed host. Facts are a convenient way to retrieve the state of a managed host and to determine what action to take based on that state. Some of the facts gathered for a managed host might include: The host name The kernel version The network interfaces The IP addresses The version of the operating system Various environment variables The number of CPUs The available or free memory The available disk space When satisfied, press ESC and then :x and Return to save and exit the file. Time to test the Playbook and Roles defined so far. Use the following command to execute the Playbook: ansible-playbook was.yml -v After execution, the Playbook should report back with a summary of jobs successfully completed (\" ok \"), changes made to the environment (the count will be less on repeated runs of this job if a previous execution of the Playbook already committed the changes \u2014 Ansible won't waste cycles repeating work that has already been carried out, unless you request it to), jobs that have failed, and so on. If no jobs failed to execute, you are ready to proceed with the lab instructions; otherwise, return to the Roles definition and the Playbook YAML files to ensure that there are no errors within your scripts.","title":"Laying the Groundwork"},{"location":"Part%203/01%20Laying%20the%20Groundwork/#_1","text":"","title":""},{"location":"Part%203/01%20Laying%20the%20Groundwork/#another-handy-feature-of-aap-is-its-ability-to-simplify-how-code-is-shared-amongst-teams-which-traditionally-becomes-challenging-and-cumbersome-at-scale-in-the-absence-of-automation","text":"Ansible employs a feature known as \" Roles \" which in essence allows a developer to define a common set of configuration steps that can then be re-used repeatedly across multiple environments. Instead of having to coordinate across teams and share duplicate instructions with different groups, the developer can take the \"write once, run anywhere\" approach of defining an automation job a single time and then making repeated use of that code (consistently) across multiple environments. In our case, we will define an Ansible Role comprised of a set of tasks needed to configure a host (our AIX partition) for a service (WebSphere Application Server). Roles, like many other aspects of Ansible, are defined using YAML files with a predefined directory structure. Roles provide a way for you to make it easier to reuse Ansible code generically. You can package, in a standardized directory structure, all the tasks, variables, files, templates, and other resources needed to provision infrastructure or deploy applications. Copy that role from project to project simply by copying the directory. You can then simply call that role from a play to execute it. Roles carry the following benefits for developers and administrators: Roles group content, allowing easy sharing of code with others Roles can be written that define the essential elements of a system type: web server, database server, Git repository, or other purpose Roles make larger projects more manageable Roles can be developed in parallel by different administrators The directory structure is still something that we have yet to \"predefine\", so let's do that next. The directory structure of a Role contains directories such as defaults, vars, tasks, files, templates, meta, and handlers \u2014 these are all \"expected\" directories (we can make use of all of them or only a subset) that Ansible Roles must be patterned against. Each directory must contain a main.yml file which provides the relevant content needed by Ansible to execute a Playbook. Let's examine the purpose of each directory type, in turn: defaults : Contains default variables for the Role; variables by default have the lowest priority, so they are easy to override. vars : Contains variables for the Role; variables in vars have a higher priority than 'default' variables. tasks : Contains the main list of steps to be executed by the Role. files : Contains files which must be copied over to the remote host. templates : Contains file templates that support modifications from the Role; in our example, we will use the Jinja2 templating language for creating templates. meta : Contains metadata for the Role, including the author, supported platforms, and dependencies. handlers : Contains handlers which can be invoked by \"notify\" directives; these are associated with the service. Ansible supports variables that can be used to store values that can then be reused throughout files in an Ansible project. This can simplify the creation and maintenance of a project and reduce the number of errors. Variables provide a convenient way to manage dynamic values for a given environment in your Ansible project. Examples of values that variables might contain include: Users to create Packages to install Services to restart Files to remove Archives to retrieve from the internet The directory structure you are to define in the steps ahead will look similar to the following diagram, with two distinct Roles names ( aix and was ), and subdirectories nestled within those parents. Execute the following instructions via your SSH console, either one at a time or all as a single statement, to create the directory structure needed for the Roles. Navigate to the correct directory first Make sure you are sitting in the /ansiblewas directory before creating the following subdirectories! mkdir -p roles/aix/tasks mkdir -p roles/aix/defaults mkdir -p roles/aix/templates mkdir -p roles/was/tasks mkdir -p roles/was/defaults mkdir -p roles/was/templates With AIX installed on the PowerVC LPAR (logical partition), you next need to modify root user settings associated with the virtual machine to increase the size of the filesystems available to it, as well as install additional dependencies and drivers needed for the environment. You will do so with modifications to the Roles associated with \" aix \" via the main.yml manifest file. Modify (or view) the YAML file using the following command: vi roles/aix/tasks/main.yml As before, you can either view the contents of the manifest (if you cloned the Github repository earlier) or craft a new one from scratch using the following template. No modifications to the template will be needed at this time. When satisfied, press ESC following by :x and Return to save your changes and exit the VI editor. --- - name: modifying root capabilities ibm.power_aix.user: state: modify name: root attributes: fsize: -1 cpu: -1 data: -1 stack: -1 core: -1 rss: -1 nofiles: -1 fsize_hard: -1 - name: Changes /tmp to 6G size aix_filesystem: filesystem: /tmp size: 6G state: present - name: Changes /var to 2G size aix_filesystem: filesystem: /var size: 2G state: present - name: Changes /opt to 4G size aix_filesystem: filesystem: /opt size: 4G state: present - name: Changes /usr to 6G aix_filesystem: filesystem: /usr size: 6G state: present - name: installing zip, unzip, GNUtar using yum yum: name: unzip, zip, tar-1.32-1 state: latest - name: Creating staging directory file: path: /tmp/im state: directory You are now prepared to craft the Playbook that Ansible will use to automate the workflow just defined for the aix Role. Use the following command to edit (or create) the was Playbook for WebSphere Application Server: vi was.yml As before, you can either view the contents of the manifest (if you cloned the Github repository earlier) or craft a new one from scratch using the following template. If you are working from the cloned template, you may have noticed that the last line of the YAML file ( #- role: was ) has been commented out \u2014 leave this unchanged for now, as you will be returning to it shortly. For now we are only concerned with the successful execution of the jobs associated with the aix Role. The template for was.yml is as follows: --- - hosts: was gather_facts: true user: root collections: - ibm.power_aix roles: - role: aix #- role: was Ansible facts are variables that are automatically discovered by Ansible on a managed host. Facts contain host-specific information that can be used just like regular variables in plays, conditionals, loops, or any other statement that depends on a value collected from a managed host. Facts are a convenient way to retrieve the state of a managed host and to determine what action to take based on that state. Some of the facts gathered for a managed host might include: The host name The kernel version The network interfaces The IP addresses The version of the operating system Various environment variables The number of CPUs The available or free memory The available disk space When satisfied, press ESC and then :x and Return to save and exit the file. Time to test the Playbook and Roles defined so far. Use the following command to execute the Playbook: ansible-playbook was.yml -v After execution, the Playbook should report back with a summary of jobs successfully completed (\" ok \"), changes made to the environment (the count will be less on repeated runs of this job if a previous execution of the Playbook already committed the changes \u2014 Ansible won't waste cycles repeating work that has already been carried out, unless you request it to), jobs that have failed, and so on. If no jobs failed to execute, you are ready to proceed with the lab instructions; otherwise, return to the Roles definition and the Playbook YAML files to ensure that there are no errors within your scripts.","title":"Another handy feature of AAP is its ability to simplify how code is shared amongst teams, which traditionally becomes challenging and cumbersome at scale in the absence of automation."},{"location":"Part%203/02%20Creating%20Roles%20for%20WAS/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . As with the aix Roles previously, you will need to craft a workflow of automation tasks that WebSphere Application Server (WAS) will require for a full deployment, covering a variety of tasks: uploading and decompressing the WAS binaries, preparing the Installation Manager, the generation of WAS binaries, the installation of WAS itself, the creation of a WAS profile, and starting up the WAS services. All of these tasks will be defined once, and made repeatable and fully automated for the future, using the was Role that you will now define. The following Ansible Modules will be invoked as part of the sequence of jobs and tasks that the automation engine performs: unarchive : Uploads files (tar, zip, tgz, ...) and decompresses them on a target system. shell : Allows the execution of commands on a target system. template : Processed by the Jinja2 templating language and used for generating dynamic files. copy : Uploads files to a target system. First, return to the was.yml Playbook that was defined earlier: vi was.yml Recall that Git-cloned template had a commented-out line towards the end of the YAML definition: this line \"- role: was\" will link the new was Role (which you will define momentarily) to the litany of operations that the Ansible Playbook will perform and interact with. If working from a cloned Git repository... If you cloned the Git template previously, un-comment the line by deleting the # symbol. Otherwise, if you crafted the YAML file from scratch, add the instruction to the end of your Playbook. The final version of the Playbook should mirror the following template: --- - hosts: was gather_facts: true user: root collections: - ibm.power_aix roles: - role: aix - role: was Press ESC and then :x and Return to save and exit the was.yml file. ATTENTION In the instructions to follow, you will be asked to gradually add more automation jobs to the was Roles that you just defined. You have two options for how to proceed here: Take advantage of the Git-cloned repository, which contains the fully-completed YAML definition, ready for immediate execution. This is the recommended path for those with Seller responsibilities. Go through and add the following jobs one at a time, in sequence, testing execution of the Playbook at each stage. This route will allow you to incrementally make changes to the Roles, test the results with the Playbook, and see for yourself the gradual progression of the installation and deployment of WebSphere Application Server. This is the recommended path for those with Technical Seller responsibilities. Either path is appropriate, so tailor it to your needs or interests. Good luck!","title":"Creating Roles for WAS"},{"location":"Part%203/03%20Staging%20and%20Execution/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . The first task that Ansible's automation will need to tackle is creation of a staging directory, where the WAS Installation Manager binaries can be downloaded and unpackaged. Begin by using the VI editor to create (or modify/examine) the main.yml Roles via the following command: vi roles/was/tasks/main.yml The /tmp/im directory will be the path designated for this purpose. 6 GB Scaling In an earlier section of this lab, you'll recall that we increased the size of this directory to 6 GB in anticipation of the added capacity needs. Once the temporary directory has been created, the Installation Manager source files will be replicated to that endpoint. The \"creates:\" statement instructs Ansible to ignore the file upload request if the data is already replicated (this will be useful on repeat executions of the Playbook, it Ansible will not attempt to duplicate the download on subsequent runs). The third job will execute the Installation Manager and accept the end-user license for use of the product. main.yml Technical Sellers : As you are defining the file from scratch, your YML file will mirror the template provided below. Sellers : Since you are working from a Git-cloned repository, there will be additional tasks and lines of code beyond what is shown below \u2014 ignore those for now. --- - name: Creating staging directory file: path: /tmp/im state: directory - name: copying IM source files unarchive: src: /files/aix/websphere/InstallationManager/1.8.9.4/aix.gtk.ppc_1.8.9004.20190423_2015.zip dest: /tmp/im creates: /tmp/im/userinstc.ini - name: installing installation manager shell: /tmp/im/installc -log /tmp/im.lof -acceptLicense Technical Sellers If you wish, you can test the Roles defined so far by executing the Playbook. You can repeat this step following every modification to the main.yml manifest. Ansible will take note of the additions made to the job sequence, repeating steps if necessary but avoiding redundant work (if a job has previously been executed). By the conclusion of this lab, all of the jobs necessary to fully install and deploy WebSphere Application Server will be in place and have been executed. If you are a SELLER (or are working with the Git-cloned template), execution of the Playbook will result in the full end-to-end deployment of WAS. The Playbook can be executed at any time using the following instruction: ansible-playbook was.yml -v When satisfied, press ESC and then :x and Return to save and exit.","title":"Creating the Staging Directory for WAS, Copying Source Files, and Executing the Installer"},{"location":"Part%203/04%20Creating%20a%20Template/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . WebSphere Installation Manager requires an XML file (known as a response file ) to detail where the installation should take place, the version of WAS to be installed, the versions of Java and other dependencies, and so on. The file must be located inside of the roles/was/templates directory and titled was90501.sdk8035.xml for the purposes of this lab. The directory structure will look like the following: AAP has a number of modules that can be used to modify existing files. These include lineinfile and blockinfile , among others. However, they are not always easy to use effectively and correctly. A much more powerful way to manage files is to template them. With this method, you can write a template configuration file that is automatically customized for the managed host when the file is deployed, using Ansible variables and facts . This can be easier to control and is less error-prone. Ansible uses the Jinja2 templating system for template files. Ansible also uses Jinja2 syntax to reference variables in Playbooks, and as such it will look structurally similar to what you have seen previously with YAML-based Playbooks. A Jinja2 template is composed of multiple elements: data, variables, and expressions. Those variables and expressions are replaced with their values when the Jinja2 template is rendered. You will see an example of this shortly after we execute the Playbook and compare how the variables defined within the XML file are changed. Edit (or create) the XML response file by executing this command: vi roles/was/templates/was90501.sdk8035.xml The variables of note, specific to this environment, are highlighted in red text. You do not need to modify this template from how it is written \u2014 these variables are highlighted only to showcase what is different from the standard Installation Manager boilerplate. Your XML file must mirror the following template before continuing with the hands-on material. <?xml version='1.0' encoding='UTF-8'?> <agent-input> <variables> <variable name='sharedLocation' value='/usr/IBM/IMShared'/> </variables> <server> <repository location='{{was_repo}}{{was_90501_file}}'/> <repository location='{{was_repo}}{{sdk_8035_file}}'/> </server> <profile id='IBM WebSphere Application Server V9.0' installLocation='/usr/IBM/WebSphere/AppServer'> <data key='cic.selector.arch' value='ppc64'/> <data key='cic.selector.ws' value='gtk'/> </profile> <install> <!-- IBM WebSphere Application Server 9.0.5.1 --> <offering profile='IBM WebSphere Application Server V9.0' id='com.ibm.websphere.BASE.v90' version='9.0.5001.20190828_0616' features='core.feature,ejbdeploy,thinclient,embeddablecontainer'/> <!-- IBM SDK, Java Technology Edition, Version 8 8.0.5.35 --> <offering profile='IBM WebSphere Application Server V9.0' id='com.ibm.java.jdk.v8' version='8.0.5035.20190422_0948' features='com.ibm.sdk.8'/> </install> <preference name='com.ibm.cic.common.core.preferences.eclipseCache' value='${sharedLocation}'/> </agent-input> When satisfied, press ESC followed by :x and Return to save and edit the file. Now you must set default variables for the WAS Roles, which will be used later when generating the response file for the Installation Manager. Edit (or create) the following YMAL template file: vi roles/was/defaults/main.yml The YAML file definition should mirror the following: was_repo: /tmp/wasrepo/ was_90501_file: was.repo.90501.base.zip sdk_8035_file: sdk.repo.8035.java8.aix.zip was_90501_source_dir: /files/aix/websphere/was/was9051/ sdk_8035_source_dir: /files/aix/websphere/sdk/sdk8035/ You are now ready to make additional modifications to the primary Playbook, instructing Ansible to generate and upload the template for WAS. Instruct the VI editor to open the Playbook with the same command used before: vi roles/was/tasks/main.yml main.yml Technical Sellers : Extend the Playbook to resemble the following template. Sellers : Leave the completed Playbook unmodified. --- - name: Creating staging directory file: path: /tmp/im state: directory - name: copying IM source files unarchive: src: /files/aix/websphere/InstallationManager/1.8.9.4/aix.gtk.ppc_1.8.9004.20190423_2015.zip dest: /tmp/im creates: /tmp/im/userinstc.ini - name: installing installation manager shell: /tmp/im/installc -log /tmp/im.lof -acceptLicense - name: uploading was installation response file template: src: templates/was90501.sdk8035.xml dest: /tmp/was90501.sdk8035.xml - name: Creating wasrepo directory file: path: \"{{was_repo}}\" state: directory - name: copying binaries to wasrepo copy: src: \"{{item}}\" dest: \"{{was_repo}}\" loop: - \"{{was_90501_source_dir}}{{was_90501_file}}\" - \"{{sdk_8035_source_dir}}{{sdk_8035_file}}\" The extensions to the Playbook will create a directory was_repo: /tmp/wasrepo/ and then instruct Ansible to upload WAS binaries to the target system. Press ESC and then :x and Return to save and exit the Playbook. Using loops saves administrators from having to write multiple tasks (repetitively and redundantly) to make use of the same module(s). For example, instead of writing five tasks to ensure five users exist, you can write one task that iterates over a list of five users to ensure they all exist. Ansible supports iterating a task over a set of items using the loop keyword. You can configure loops to repeat a task using each item in a list, the contents of each of the files in a list, a generated sequence of numbers, or using more complicated structures. Technical Sellers As before, you can execute the Playbook at this stage to carry out the new modifications that have been added since the last execution. ansible-playbook was.yml -v","title":"Creation of a Template"},{"location":"Part%203/05%20Launching%20WAS/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . Further modifications to the primary Playbook are required to complete the installation of WAS, generate the necessary profiles, and fully launch the software. Once again, edit the Playbook YAML manifest. main.yml Technical Sellers : Extend the YAML file as you have done previously so that the final version matches the template documented below. Sellers : As you are working from a completed YAML file that was cloned from the Git repository, you do not need to make any modifications to the file. vi roles/was/defaults/main.yml The finalized Playbook should exactly mirror the following template: --- - name: Creating staging directory file: path: /tmp/im state: directory - name: copying IM source files unarchive: src: /files/aix/websphere/InstallationManager/1.8.9.4/aix.gtk.ppc_1.8.9004.20190423_2015.zip dest: /tmp/im creates: /tmp/im/userinstc.ini - name: installing installation manager shell: /tmp/im/installc -log /tmp/im.lof -acceptLicense - name: uploading was installation response file template: src: templates/was90501.sdk8035.xml dest: /tmp/was90501.sdk8035.xml - name: Creating wasrepo directory file: path: \"{{was_repo}}\" state: directory - name: copying binaries to wasrepo copy: src: \"{{item}}\" dest: \"{{was_repo}}\" loop: - \"{{was_90501_source_dir}}{{was_90501_file}}\" - \"{{sdk_8035_source_dir}}{{sdk_8035_file}}\" - name: installing was using Installation manager shell: /opt/IBM/InstallationManager/eclipse/tools/imcl input /tmp/was90501.sdk8035.xml -acceptlicense tags: template - name: creating was profile shell: /usr/IBM/WebSphere/AppServer/bin/manageprofiles.sh -create -templatePath /usr/IBM/WebSphere/AppServer/profileTemplates/default tags: template - name: starting application server shell: /usr/IBM/WebSphere/AppServer/profiles/AppSrv01/bin/startServer.sh server1 tags: template When satisfied, press ESC and :x and Return to save and exit the YAML file. Finally, execute the completed Playbook. Sellers and Technical Sellers This step must be performed by both Sellers and Technical Sellers . ansible-playbook was.yml -v Wait until the Playbook has finished executing and the \" PLAY RECAP \" has been printed to screen within the Terminal console. Successful execution of the full Playbook may take several minutes to complete. If all jobs have successfully been executed (with status as \" OK \"), then WebSphere Application Server should now be successfully installed on the AIX LPAR and the services now live for you to interact with! Test that WebSphere Application Server is now online by visiting the following address with your Web browser: http://10.3.XX.XX:9060/ibm/console Host Address Substitute the missing variables with the IP address of your AIX LPAR (this is the address summarized just below the PLAY RECAP in the screenshot above) \u2014 remember to use the address unique to your environment. Ensure that you are connected to OpenVPN tunnel used earlier before attempting to access the WAS service. You may input any userID that you wish and then click Log In (remember that we disabled authentication in an earlier step) to access the WAS dashboard. Congratulations \u2014 you have successfully installed and deployed a WebSphere Application Server environment on PowerVC entirely using Red Hat Ansible Automation Platform! Business Partners Keep your browser window open to the WAS dashboard. The following series of questions will be repeated on your L3 accreditation quiz . Use this time to investigate the various areas of the WAS dashboard so that you can prepare for the quiz and quickly certify your completion of this hands-on material. IBM Sellers and Technical Sellers Begin planning how you wish to present and record your Stand & Deliver . Replicate the steps and lessons learned throughout this hands-on material and ensure that your recording meets all of the evaluation criteria outlined in the Stand & Deliver requirements.","title":"Installation of WAS, Creation of a Profile, and Launching the Software"},{"location":"Part%203/05%20Launching%20WAS/#_1","text":"","title":""},{"location":"Part%203/05%20Launching%20WAS/#congratulations-you-have-successfully-installed-and-deployed-a-websphere-application-server-environment-on-powervc-entirely-using-red-hat-ansible-automation-platform","text":"Business Partners Keep your browser window open to the WAS dashboard. The following series of questions will be repeated on your L3 accreditation quiz . Use this time to investigate the various areas of the WAS dashboard so that you can prepare for the quiz and quickly certify your completion of this hands-on material. IBM Sellers and Technical Sellers Begin planning how you wish to present and record your Stand & Deliver . Replicate the steps and lessons learned throughout this hands-on material and ensure that your recording meets all of the evaluation criteria outlined in the Stand & Deliver requirements.","title":"Congratulations \u2014 you have successfully installed and deployed a WebSphere Application Server environment on PowerVC entirely using Red Hat Ansible Automation Platform!"},{"location":"Part%204/01%20Business%20Partner%20Accreditation/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . Warning To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. Business Partners must pass an accreditation quiz after completing the hands-on portion of the course. The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. The quiz questions are based on elements of the WebSphere Application Server (WAS) web dashboard, which you will be asked to investigate and record specific details about. The WAS environment and dashboard will be available to you after you have successfully concluded the lab work \u2014 remaining online until your ITZ reservation has expired. Expiring environments Note that the ITZ environment can only be reserved for 4 hours at a time. After this period, the instance will automatically be retired and deprovisioned. It is strongly recommended that you complete your investigations for the quiz questions (below) before that time has expired. If not, you will need to run through the lab work another time to bring the WAS environment back online. Record your answers now so that you can quickly answer the accreditation quiz questions later .","title":"Business Partner Accreditation"},{"location":"Part%204/01%20Business%20Partner%20Accreditation/#_1","text":"","title":""},{"location":"Part%204/01%20Business%20Partner%20Accreditation/#business-partners-must-pass-an-accreditation-quiz-after-completing-the-hands-on-portion-of-the-course","text":"The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. The quiz questions are based on elements of the WebSphere Application Server (WAS) web dashboard, which you will be asked to investigate and record specific details about. The WAS environment and dashboard will be available to you after you have successfully concluded the lab work \u2014 remaining online until your ITZ reservation has expired. Expiring environments Note that the ITZ environment can only be reserved for 4 hours at a time. After this period, the instance will automatically be retired and deprovisioned. It is strongly recommended that you complete your investigations for the quiz questions (below) before that time has expired. If not, you will need to run through the lab work another time to bring the WAS environment back online. Record your answers now so that you can quickly answer the accreditation quiz questions later .","title":"Business Partners must pass an accreditation quiz after completing the hands-on portion of the course."},{"location":"Part%204/02%20IBMer%20Accreditation/","text":"Ways to watch In addition to the embedded video, IBMers and Business Partners can also download the recording from Seismic . Warning To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. IBM Sellers and Technical Sellers must develop and record a Stand & Deliver presentation. This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the environments and techniques covered through this lab. IBMers will be evaluated by First Line Manager (FLM). Instructions on how to submit a Stand & Deliver via Allego are included on the YourLearning coursework page . The evaluation criteria that your FLM will weigh your performance against are as follows: Seller articulated client's pain point (s) and the value proposition of using Ansible Automation Platform. Seller highlighted use cases for Ansible Automation Platform. Seller demonstrated and discussed several of the key differentiated capabilities of Ansible Automation Platform that deliver on the value proposition on point one. Seller highlighted benefits to the client (this is the why the client can\u2019t live without these benefits section). Seller highlighted benefits to the client's customers (what will the client be able to deliver to their customers that they could not without this product). Seller closed the demo with a call to action for the client that could include: a workshop, a deeper dive into the product meeting, MVP engagements, and so on. Keys to success Be sure to incorporate each of these themes and topics into your Stand & Deliver recording, touching on each of them as you run through an end-to-end delivery of the full lab. Good luck!","title":"IBM Seller and Technical Seller Accreditation"},{"location":"Part%204/02%20IBMer%20Accreditation/#_1","text":"","title":""},{"location":"Part%204/02%20IBMer%20Accreditation/#ibm-sellers-and-technical-sellers-must-develop-and-record-a-stand-deliver-presentation","text":"This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the environments and techniques covered through this lab. IBMers will be evaluated by First Line Manager (FLM). Instructions on how to submit a Stand & Deliver via Allego are included on the YourLearning coursework page . The evaluation criteria that your FLM will weigh your performance against are as follows: Seller articulated client's pain point (s) and the value proposition of using Ansible Automation Platform. Seller highlighted use cases for Ansible Automation Platform. Seller demonstrated and discussed several of the key differentiated capabilities of Ansible Automation Platform that deliver on the value proposition on point one. Seller highlighted benefits to the client (this is the why the client can\u2019t live without these benefits section). Seller highlighted benefits to the client's customers (what will the client be able to deliver to their customers that they could not without this product). Seller closed the demo with a call to action for the client that could include: a workshop, a deeper dive into the product meeting, MVP engagements, and so on. Keys to success Be sure to incorporate each of these themes and topics into your Stand & Deliver recording, touching on each of them as you run through an end-to-end delivery of the full lab. Good luck!","title":"IBM Sellers and Technical Sellers must develop and record a Stand &amp; Deliver presentation."}]}